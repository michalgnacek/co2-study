{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0390454e-e4cc-4202-88e4-16bdcc4812ae",
   "metadata": {},
   "source": [
    "# Machine learning - multimodal regression for GSR using other modalities\n",
    "\n",
    "*This notebook contains initial work on regression model for target GSR using other physiological signals. This work was out of scope of the initial paper and is incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if('notebooks' in os.getcwd()):\n",
    "    os.chdir('..')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bee7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory for notebook output\n",
    "notebook_temp_dir = os.path.join(os.getcwd(), \"temp\", \"5_multimodal_regression\")\n",
    "\n",
    "if not os.path.exists(notebook_temp_dir):\n",
    "    os.makedirs(notebook_temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "features_file_directory = os.path.join(os.getcwd(), 'temp', 'windowed_features.csv')\n",
    "df = pd.read_csv(features_file_directory, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02202bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Segment']=='gas_inhalation']\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "data = df  # Replace with your data file path\n",
    "\n",
    "\n",
    "# Filter columns that contain 'Emg/Contact[RightOrbicularis]', 'Emg/Contact[LeftOrbicularis]', 'Emg/Contact[RightZygomaticus]', 'Emg/Contact[LeftZygomaticus]', or 'Biopac_GSR_mean' in their names\n",
    "#selected_columns = [col for col in data.columns if 'Emg/Contact[RightOrbicularis]' in col \n",
    "#                                                 or 'Emg/Contact[LeftOrbicularis]' in col \n",
    "#                                                 or 'Emg/Contact[RightZygomaticus]' in col \n",
    "#                                                 or 'Emg/Contact[LeftZygomaticus]' in col \n",
    "#                                                 or col == 'Biopac_GSR_mean'\n",
    "#                                                 or col == 'Condition'\n",
    "#                                                 or col == 'Segment'\n",
    "#                                                 or col == 'participant_number']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "#data = data[selected_columns]\n",
    "\n",
    "# Initialize lists to store evaluation results\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "\n",
    "# Initialize lists to store actual and predicted values\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "# Initialize lists to store average mean values for actual and predicted GSR\n",
    "average_actual_means = []\n",
    "average_predicted_means = []\n",
    "\n",
    "# Initialize an array to accumulate feature importances across all participants\n",
    "total_feature_importances = []\n",
    "\n",
    "\n",
    "# Iterate through each participant for leave-one-subject-out cross-validation\n",
    "unique_participants = data['participant_number'].unique()\n",
    "for participant in unique_participants:\n",
    "    print(\"Running ML for participant:\" + participant)\n",
    "    # Split data into training and validation sets\n",
    "    train_data = data[data['participant_number'] != participant]\n",
    "    #train_data = train_data[train_data['Condition']=='CO2']\n",
    "    val_data = data[data['participant_number'] == participant]\n",
    "    #val_data = val_data[val_data['Condition']=='CO2']\n",
    "\n",
    "    # Select features and target for training and validation\n",
    "    X_train = train_data.drop(['participant_number', 'Condition', 'Segment'], axis=1)\n",
    "    y_train = train_data['Biopac_GSR_mean']\n",
    "    X_val = val_data.drop(['participant_number', 'Condition', 'Segment'], axis=1)\n",
    "    y_val = val_data['Biopac_GSR_mean']\n",
    "\n",
    "    # Drop columns that start with specified prefixes\n",
    "    #drop_columns = [col for col in X_train.columns if col.startswith(('Biopac', 'RSP', 'SCR', 'EDA'))]\n",
    "    drop_columns = [col for col in X_train.columns if col.startswith(('Biopac_GSR', 'SCR', 'EDA'))]\n",
    "    X_train = X_train.drop(drop_columns, axis=1)\n",
    "    X_val = X_val.drop(drop_columns, axis=1)\n",
    "\n",
    "    # Initialize and train a Ridge Regressor\n",
    "    model = Ridge(alpha=1.0)  # You can adjust the alpha value for regularization strength\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the learned coefficients (feature importances) from the trained model\n",
    "    participant_feature_importances = model.coef_\n",
    "\n",
    "    # Accumulate the feature importances for this participant\n",
    "    total_feature_importances.append(participant_feature_importances)\n",
    "\n",
    "    # Predict GSR values on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mae_scores.append(mean_absolute_error(y_val, y_val_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_val, y_val_pred, squared=False))\n",
    "    r2_scores.append(r2_score(y_val, y_val_pred))\n",
    "    \n",
    "    # Append actual and predicted values for this participant\n",
    "    all_actual_values.extend(y_val)\n",
    "    all_predicted_values.extend(y_val_pred)\n",
    "    \n",
    "    # Calculate and append average mean for actual and predicted GSR values for this participant\n",
    "    average_actual_mean = y_val.mean()\n",
    "    average_predicted_mean = y_val_pred.mean()\n",
    "    average_actual_means.append(average_actual_mean)\n",
    "    average_predicted_means.append(average_predicted_mean)\n",
    "    \n",
    "    # Assuming y_val_pred and y_val are NumPy arrays or Pandas Series\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "    # Plot the predicted values\n",
    "    plt.plot(y_val_pred, label='Predicted')\n",
    "\n",
    "    # Plot the actual values\n",
    "    plt.plot(y_val.reset_index(drop=True), label='Actual')\n",
    "    plt.legend()\n",
    "\n",
    "# Calculate average MAE, RMSE, R-squared\n",
    "avg_mae = sum(mae_scores) / len(mae_scores)\n",
    "avg_rmse = sum(rmse_scores) / len(rmse_scores)\n",
    "avg_r2 = sum(r2_scores) / len(r2_scores)\n",
    "\n",
    "print(f\"Average Mean Absolute Error: {avg_mae:.2f}\")\n",
    "print(f\"Average Root Mean Squared Error: {avg_rmse:.2f}\")\n",
    "print(f\"Average R-squared: {avg_r2:.2f}\")\n",
    "\n",
    "# Scatter Plot: Predicted vs Actual GSR values for all participants\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=all_actual_values, y=all_predicted_values)\n",
    "plt.xlabel('Actual GSR')\n",
    "plt.ylabel('Predicted GSR')\n",
    "plt.title('Scatter Plot: Actual vs Predicted GSR (All Participants)')\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot: Average Evaluation Scores\n",
    "evaluation_metrics = ['MAE', 'RMSE', 'R-squared']\n",
    "average_scores = [avg_mae, avg_rmse, avg_r2]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=evaluation_metrics, y=average_scores)\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('Bar Plot: Average Evaluation Scores')\n",
    "plt.show()\n",
    "\n",
    "# Line Plot: Average Mean Predicted vs Actual GSR values across participants\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_participants, average_actual_means, label='Actual GSR', marker='o')\n",
    "plt.plot(unique_participants, average_predicted_means, label='Predicted GSR', marker='o')\n",
    "plt.xlabel('Participant')\n",
    "plt.ylabel('Average Mean GSR Value')\n",
    "plt.title('Line Plot: Average Mean Actual vs Predicted GSR across Participants')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average feature importances\n",
    "average_feature_importances = sum(total_feature_importances) / len(unique_participants)\n",
    "\n",
    "# Create a DataFrame to associate feature names with their corresponding average importance values\n",
    "average_feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Average_Importance': average_feature_importances})\n",
    "average_feature_importance_df = average_feature_importance_df.sort_values(by='Average_Importance', ascending=False)\n",
    "\n",
    "# Print the average feature importances\n",
    "print(\"Average Feature Importances:\")\n",
    "print(average_feature_importance_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sideways bar plot showing the top 10 most important features\n",
    "top_features = average_feature_importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Average_Importance', y='Feature', data=top_features, orient='h')\n",
    "plt.xlabel('Average Importance')\n",
    "plt.ylabel('')\n",
    "plt.title('20 Most Relevant Features')\n",
    "# Adjust the left margin to make sure y-axis labels are not cut off\n",
    "plt.subplots_adjust(left=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(notebook_temp_dir, 'regression_feature_importance.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the individual R-squared scores\n",
    "r2_df = pd.DataFrame({'Participant': unique_participants, 'R-squared': r2_scores})\n",
    "\n",
    "# Extract participant numbers from the labels\n",
    "r2_df['Participant'] = r2_df['Participant'].str.split('_').str[0]\n",
    "\n",
    "# Determine colors based on R-squared value ranges\n",
    "def assign_color(r2_value):\n",
    "    if r2_value >= 0.75:\n",
    "        return 'green'\n",
    "    elif r2_value >= 0.5:\n",
    "        return 'yellow'\n",
    "    elif r2_value >= 0.25:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "# Determine colors based on R-squared values\n",
    "colors = r2_df['R-squared'].apply(assign_color)\n",
    "\n",
    "# Create a bar plot of individual R-squared scores with extracted participant numbers and colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Participant', y='R-squared', data=r2_df, palette=colors)\n",
    "plt.title('Ridge Regression for target GSR using all features')\n",
    "plt.xlabel('Participant')\n",
    "plt.ylabel('R-squared')\n",
    "# Create a custom legend for the color range\n",
    "legend_labels = {\n",
    "    'green': 'R-squared >= 0.75',\n",
    "    'yellow': '0.75 > R-squared >= 0.5',\n",
    "    'orange': '0.5 > R-squared >= 0.25',\n",
    "    'red': 'R-squared < 0.25'\n",
    "}\n",
    "handles = [plt.Line2D([], [], color=color, label=label, linewidth=6) for color, label in legend_labels.items()]\n",
    "plt.legend(handles=handles, title='R-squared Range')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(notebook_temp_dir, 'regression_results.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36ad43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into a DataFrame (replace 'df' with your data file)\n",
    "data = df\n",
    "\n",
    "feature_names = data.drop(['participant_number', 'Condition', 'Segment', 'Biopac_GSR_mean'], axis=1).columns.tolist()\n",
    "\n",
    "# Get unique participant numbers\n",
    "unique_participants = data['participant_number'].unique()\n",
    "\n",
    "# Initialize a dictionary to store performance metrics for each feature\n",
    "feature_performance = {}\n",
    "\n",
    "# Iterate through each feature\n",
    "for feature in feature_names:\n",
    "    print(f\"Running ML for feature: {feature}\")\n",
    "    \n",
    "    # Initialize lists to store performance metrics for each participant\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    # Iterate through each participant\n",
    "    for participant in unique_participants:\n",
    "        # Select data for the current participant\n",
    "        #val_data = data[(data['participant_number'] == participant) & (data['Condition'] == 'CO2')]\n",
    "        #train_data = data[(data['participant_number'] != participant) & (data['Condition'] == 'CO2')]\n",
    "        \n",
    "        val_data = data[(data['participant_number'] == participant)]\n",
    "        train_data = data[(data['participant_number'] != participant)]\n",
    "        \n",
    "        # Select features and target for training and validation\n",
    "        X_train = train_data[[feature]]\n",
    "        y_train = train_data['Biopac_GSR_mean']\n",
    "        X_val = val_data[[feature]]\n",
    "        y_val = val_data['Biopac_GSR_mean']\n",
    "        \n",
    "        # Train Ridge Regressor\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict GSR values on validation set\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate Mean Squared Error (MSE) and R-squared for the current participant\n",
    "        mse = mean_squared_error(y_val, y_val_pred)\n",
    "        r2 = r2_score(y_val, y_val_pred)\n",
    "        \n",
    "        # Append the scores to the lists\n",
    "        mse_scores.append(mse)\n",
    "        r2_scores.append(r2)\n",
    "    \n",
    "    # Calculate the average performance metrics for the current feature\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    \n",
    "    # Store the average performance metrics in the dictionary\n",
    "    feature_performance[feature] = {'Avg MSE': avg_mse, 'Avg R-squared': avg_r2}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "feature_performance_df = pd.DataFrame.from_dict(feature_performance, orient='index')\n",
    "\n",
    "# Print the average performance metrics for each feature\n",
    "print(\"Average Performance Metrics per Feature:\")\n",
    "print(feature_performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b90d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
